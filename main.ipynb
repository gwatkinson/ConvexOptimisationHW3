{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convex Optimization - Homework 3\n",
    "\n",
    "<font color='lightgreen'>\n",
    "\n",
    "<i>Report plots, comments and theoretical results in a pdf file. Send your code together with the requested functions and a main script reproducing all your experiments. You can use Matlab, Python or Julia.</i>\n",
    "\n",
    "Given $x_1,...,x_n \\in \\mathbb{R}^d$ data vectors and $y_1,...,y_n \\in \\mathbb{R}$ observations, we are searching for regression parameters $w \\in \\mathbb{R}^d$ which fit data inputs to observations $y$ by minimizing their squared difference. In a high dimensional setting (when $n \\ll d$) a $l_1$ norm penalty is\n",
    "often used on the regression coefficients $w$ in order to enforce sparsity of the solution (so that $w$ will only have a few non-zeros entries). Such penalization has well known statistical properties, and makes the model both more interpretable, and faster at test time. \n",
    "\n",
    "From an optimization point of view we want to solve the following problem called LASSO (which stands for Least Absolute Shrinkage Operator and Selection Operator)\n",
    "\n",
    "\\begin{equation}\n",
    "\\tag{LASSO}\n",
    "\\begin{array}{ll}\n",
    "\\text{minimize} & \\frac{1}{2} \\left\\lVert Xw - y \\right\\rVert^2_2 + \\lambda \\left\\lVert w \\right\\rVert_1\n",
    "\\end{array}\n",
    "\\end{equation}\n",
    "\n",
    "in the variable $w \\in \\mathbb{R}^d$, where $X = (x^T_1, \\ldots, x^T_n) \\in \\mathbb{R}^{n\\times d},\\, y = (y_1, \\ldots, y_n) \\in \\mathbb{R}^n$ and $\\lambda \\ge 0$ is a regularization parameter.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='lightblue'>\n",
    "1. Derive the dual problem of LASSO and format it as a general Quadratic Problem as follows\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "\\tag{QP}\n",
    "\\begin{array}{ll}\n",
    "\\text{minimize} & v^TQv + p^Tv \\\\\n",
    "\\text{subject to} & Av \\preceq b\n",
    "\\end{array}\n",
    "\\end{equation}\n",
    "\n",
    "in variable $v\\in \\mathbb{R}^n$, where $Q \\succeq 0$.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='lightblue'>\n",
    "2. Impliment the barrier method to solve QP.\n",
    "\n",
    "- Write a function `v_seq = centering_step(Q, p, A, b, t, v0, eps)` which impliments the Newton method to solve the centering step given the inputs $(Q, p, A, b)$, the barrier method parameter $t$ (see lectures), initial variable $v_0$ and a target precision $\\epsilon$. The function outputs the sequence of variables iterates $(v_i)_{i=1, \\ldots, n_{\\epsilon}}$, where $n_{\\epsilon}$ is the number of iterations to obtain the $\\epsilon$ precision. Use a backtracking line search with appropriate parameters.\n",
    "- Write a function `v_seq = barr_method(Q, p, A, b, v0, eps)` which implements the barrier method to solve QP using precedent function given the data inputs $(Q, p, A, b)$, a feasible point $v_0$, a precision criterion $\\epsilon$. The function ouptuts the sequence of variables iterates $(v_i)_{i=1, \\ldots, n_{\\epsilon}}$, where $n_{\\epsilon}$ is the number of iterations to obtain the $\\epsilon$ precision.\n",
    "- Test your function on randomly generated matrices $X$ and observations $y$ withz $\\lambda = 10$. Plot precision criterion and gap $f(v_t) - f^*$ in semilog scale (using the best value found for $f$ as a surrogate for $f^*$). Repeat for different values of the barrier method parameter $\\mu = 2, 15, 50, 100, \\ldots$ and check the impact on $w$. What would be an appropriate choice for $\\mu$ ?\n",
    "</font>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
